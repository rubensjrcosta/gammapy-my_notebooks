{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec35692b",
   "metadata": {},
   "source": [
    "[![gammapy](https://img.shields.io/badge/powered%20by-gammapy-orange.svg?style=flat)](https://gammapy.org/)\n",
    "\n",
    "# Gammapy Part II: Spectral Analysis \n",
    "**Tutors:** Rubens Costa Jr.\n",
    "\n",
    "This hands-on tutorial gives an introduction and overview of [Gammapy](https://gammapy.org/). \n",
    "In the first part of the this tutorial we learned about the basic data structures in Gammapy using [Third Fermi-LAT Catalog of High-Energy Sources (3FHL) catalog](http://fermi.gsfc.nasa.gov/ssc/data/access/lat/3FHL/), in this second part we will perform a spectral analysis using simulated CTA data.\n",
    "\n",
    "## Preface\n",
    "We recommend to follow this tutorial by **executing the code cells on your local machine**, along with the tutor. The estimated time for this part of the tutorial is ~30 minutes.\n",
    "\n",
    "We're happy to receive any **feedback or questions** on the tutorial via mail to *rubensjrcosta@gmail.com*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb5772",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851fa1a",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "üîù [Back to Top](#intro)<br>\n",
    "## 2. Setup \n",
    "\n",
    "**Important**: to run this tutorial the environment variable `GAMMAPY_DATA` must be defined and point to the directory on your machine where the datasets needed are placed. To check whether your setup is correct you can execute the following cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eadd25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os # Miscellaneous operating system interfaces\n",
    "\n",
    "path = os.path.expandvars(\"$GAMMAPY_DATA\")\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    raise Exception(\"gammapy-data repository not found!\")\n",
    "else:\n",
    "    print(\"Great your setup is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a72ee",
   "metadata": {},
   "source": [
    "In case you encounter an error, you can un-comment and execute the following cell to continue. But we recommend to set up your environment correctly as described in [getting started](https://docs.gammapy.org/dev/getting-started/index.html#download-tutorials) after you are done with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac87015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.environ['GAMMAPY_DATA'] = os.path.join(os.getcwd(), '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855d156",
   "metadata": {},
   "source": [
    "Now we can continue with the usual IPython notebooks and Python imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7415f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display figures directly inline\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt # A collection of command style functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7bae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I'd like to ignore some deprecation warnings by matplotlib\n",
    "# This in general not advised, but for this specific notebook\n",
    "from matplotlib import MatplotlibDeprecationWarning # A class for issuing deprecation warnings \n",
    "\n",
    "import warnings # Warning control\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=MatplotlibDeprecationWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f31df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gammapy\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "import collections\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from gammapy.makers import SpectrumDatasetMaker, SafeMaskMaker, ReflectedRegionsBackgroundMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.data import Observation, Observations\n",
    "from gammapy.datasets import SpectrumDatasetOnOff, SpectrumDataset, Datasets\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.maps import MapAxis, RegionGeom, WcsNDMap, WcsGeom\n",
    "\n",
    "from gammapy.modeling.models import (\n",
    "    EBLAbsorptionNormSpectralModel,\n",
    "    Models,\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    ExpCutoffPowerLawSpectralModel\n",
    ")\n",
    "\n",
    "from gammapy.irf import EffectiveAreaTable2D\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "from gammapy.estimators import FluxPoints\n",
    "from gammapy.datasets import FluxPointsDataset\n",
    "\n",
    "# astropy imports\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "\n",
    "from gammapy.estimators import SensitivityEstimator\n",
    "\n",
    "# astropy affiliated packages imports\n",
    "from regions import CircleSkyRegion\n",
    "\n",
    "from gammapy.stats import WStatCountsStatistic\n",
    "from gammapy.stats import CashCountsStatistic\n",
    "from scipy.stats import sem\n",
    "from gammapy.maps import Map\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d510e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define simulation parameters parameters\n",
    "livetimes = [2.21] * u.h # Livetime exposure of the simulated observation\n",
    "sites = ['North'] # CTA North\n",
    "irftime = '0.5h' #  Observation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882afa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "on_region_radius = Angle(\"0.11 deg\")\n",
    "alpha = 0.2  # acceptance_off=1./alpha) # Relative background efficiency in the off region\n",
    "emin = 1 * u.GeV\n",
    "emax = 100. * u.TeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d79e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We simulate each observation n_obs times, to randomize the renortets:\n",
    "n_obs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251454f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_simulated = pd.read_csv('bllac_norte_1x/bllac_norte_1x.txt', sep='  ', engine='python')\n",
    "display(df_simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd594de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_obs = df_simulated.sample(n = 2).reset_index(drop=True)\n",
    "selected_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052c2bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_obs.to_string('bllac_norte_1x/selected_obs.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f342e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_name, ra_pointing, dec_pointing, ra, dec, red, luminosity, index, amplitude, IRF_zen, offset = np.loadtxt('bllac_norte_1x/selected_obs.txt', skiprows=1, unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4405e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6817a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitbackend = 'minuit'\n",
    "optimize_opts = {'tol': 0.1, 'strategy': 1, 'print_level': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b74364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = {'Source_Name': [],\n",
    "          'RA_pointing': [],\n",
    "          'DEC_pointing': [],\n",
    "          'RAJ2000': [],\n",
    "          'DEJ2000': [],\n",
    "          'Redshift': [],\n",
    "          'Amplitude': [],\n",
    "          'Index': [],\n",
    "          'Luminosity': [],\n",
    "          'Offset': [],\n",
    "          'Site': [],\n",
    "          'Irf_Zen_pointing': [],\n",
    "          'Irf_Time': [],\n",
    "          'Livetime_pointing': [],\n",
    "          'Emin': [],\n",
    "          'Ethreshold': [],\n",
    "          'AboveEthFlag': [],\n",
    "          'Model_Name': [],\n",
    "          'N_sims' : [],\n",
    "          'N_failed' : [],\n",
    "          'Bkg': [],\n",
    "          'Significance': [],\n",
    "          'Energy0': [],\n",
    "          'Energy1': [],\n",
    "          'eref0': [],\n",
    "          'eref1': [],\n",
    "          'eref2': [],\n",
    "          'eref3': [],\n",
    "          'eref4': [],\n",
    "          'eref5': [],\n",
    "          'eref6': [],\n",
    "          'eref7': [],\n",
    "          'eref8': [],\n",
    "          'eref9': [],\n",
    "          'eref10': [],\n",
    "          'eref11': [],\n",
    "          'emin0': [],\n",
    "          'emin1': [],\n",
    "          'emin2': [],\n",
    "          'emin3': [],\n",
    "          'emin4': [],\n",
    "          'emin5': [],\n",
    "          'emin6': [],\n",
    "          'emin7': [],\n",
    "          'emin8': [],\n",
    "          'emin9': [],\n",
    "          'emin10': [],\n",
    "          'emin11': [],\n",
    "          'emax0': [],\n",
    "          'emax1': [],\n",
    "          'emax2': [],\n",
    "          'emax3': [],\n",
    "          'emax4': [],\n",
    "          'emax5': [],\n",
    "          'emax6': [],\n",
    "          'emax7': [],\n",
    "          'emax8': [],\n",
    "          'emax9': [],\n",
    "          'emax10': [],\n",
    "          'emax11': [],\n",
    "          'dnde0': [],\n",
    "          'dnde1': [],\n",
    "          'dnde2': [],\n",
    "          'dnde3': [],\n",
    "          'dnde4': [],\n",
    "          'dnde5': [],\n",
    "          'dnde6': [],\n",
    "          'dnde7': [],\n",
    "          'dnde8': [],\n",
    "          'dnde9': [],\n",
    "          'dnde10': [],\n",
    "          'dnde11': [],\n",
    "          'dnde_err0': [],\n",
    "          'dnde_err1': [],\n",
    "          'dnde_err2': [],\n",
    "          'dnde_err3': [],\n",
    "          'dnde_err4': [],\n",
    "          'dnde_err5': [],\n",
    "          'dnde_err6': [],\n",
    "          'dnde_err7': [],\n",
    "          'dnde_err8': [],\n",
    "          'dnde_err9': [],\n",
    "          'dnde_err10': [],\n",
    "          'dnde_err11': [],\n",
    "          'amplitude_fit': [],\n",
    "          'amplitude_err_fit': [],\n",
    "          'index_fit': [],\n",
    "          'index_err_fit': [],\n",
    "          'reference_fit': [],\n",
    "          'int_sens': []\n",
    "\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e7e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in range(len(name)):\n",
    "for i in range(len(selected_obs)):\n",
    "    print(f\"\"\"#################### source_name = {source_name[i]} ####################\"\"\")\n",
    "    \n",
    "    # Define Target Region\n",
    "    # source position\n",
    "    src_position = SkyCoord(\n",
    "        ra[i], \n",
    "        dec[i], \n",
    "        unit=\"deg\", \n",
    "        frame=\"icrs\"\n",
    "    )\n",
    "    \n",
    "    # observation region\n",
    "    on_region = CircleSkyRegion(\n",
    "        center=src_position, \n",
    "        radius=on_region_radius\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Define simulation parameters\n",
    "    pointing = SkyCoord(\n",
    "         ra_pointing[i], \n",
    "         dec_pointing[i], \n",
    "         unit=\"deg\", \n",
    "         frame=\"icrs\"\n",
    "     )\n",
    "    \n",
    "    # Define spectral model - a simple Power Law in this case\n",
    "    specmodel = PowerLawSpectralModel(\n",
    "        amplitude=amplitude[i] * u.Unit('cm^-2 s^-1 MeV^-1'),\n",
    "        reference=1 * u.Unit('MeV'),\n",
    "        index=index[i]\n",
    "    )\n",
    "    \n",
    "    # EBL absorbption spectral model\n",
    "    absorption = EBLAbsorptionNormSpectralModel.read_builtin(\n",
    "        \"finke\", # Available model in gammapy-data:{'franceschini', 'dominguez', 'finke'}\n",
    "        redshift=red[i]\n",
    "    )\n",
    "    \n",
    "    absspecmodel = specmodel * absorption\n",
    "\n",
    "    skymodel = SkyModel(\n",
    "        spectral_model=absspecmodel, \n",
    "        name=\"crab\"\n",
    "    )\n",
    "    \n",
    "    obs1 = Observation.create(\n",
    "        pointing=pointing, \n",
    "        livetime=livetimes, # Livetime exposure of the simulated observation\n",
    "        irfs=load_cta_irfs('/home/bornagain/Documents/GitHub/gammapy/gammapy-notebooks/0.20.1/tutorials/data/caldb/data/cta/prod3b-v2/bcf/North_z'+str(int(IRF_zen[i]))+'_0.5h/irf_file.fits')\n",
    "    )\n",
    "    obs = [obs1]\n",
    "\n",
    "    AboveEthFlag = True\n",
    "    \n",
    "    # reconstructed energy\n",
    "    energy_reco = MapAxis.from_energy_bounds(\n",
    "        emin, \n",
    "        emax, \n",
    "        nbin=5, \n",
    "        per_decade=True, \n",
    "        name=\"energy\"\n",
    "    )\n",
    "    \n",
    "    # true energy should be wider than reconstructed energy\n",
    "    energy_true = MapAxis.from_energy_bounds(\n",
    "        0.3*emin, \n",
    "        3*emax, \n",
    "        nbin=8, \n",
    "        per_decade=True, \n",
    "        name=\"energy_true\"\n",
    "    )\n",
    "\n",
    "    significances = []\n",
    "\n",
    "    # Make the SpectrumDataset from observation parameters\n",
    "    geom = RegionGeom.create(\n",
    "        region=on_region, \n",
    "        axes=[energy_reco]\n",
    "    )\n",
    "    \n",
    "    # Make the SpectrumDataset\n",
    "    dataset_empty = SpectrumDataset.create(\n",
    "        geom=geom, \n",
    "        energy_axis_true=energy_true, \n",
    "        name=int(source_name[i])\n",
    "    )\n",
    "    \n",
    "    # The irfs and background are computed at a single fixed offset\n",
    "    maker = SpectrumDatasetMaker(\n",
    "        # Apply containment correction for point sources and circular on regions\n",
    "        containment_correction=True, \n",
    "        # Selecting which maps to make\n",
    "        selection=[\"edisp\", \"background\", \"exposure\"]\n",
    "    )\n",
    "    \n",
    "    # Make safe data range mask for a given observation\n",
    "    safe_maker = SafeMaskMaker(methods=[\"bkg-peak\"])\n",
    "\n",
    "    n_sims = 0\n",
    "    n_failed = 0\n",
    "    significance=[]\n",
    "    eref0 = []\n",
    "    eref1 = []\n",
    "    eref2 = []\n",
    "    eref3 = []\n",
    "    eref4 = []\n",
    "    eref5 = []\n",
    "    eref6 = []\n",
    "    eref7 = []\n",
    "    eref8 = []\n",
    "    eref9 = []\n",
    "    eref10 = []\n",
    "    eref11 = []\n",
    "    emin0 = []\n",
    "    emin1 = []\n",
    "    emin2 = []\n",
    "    emin3 = []\n",
    "    emin4 = []\n",
    "    emin5 = []\n",
    "    emin6 = []\n",
    "    emin7 = []\n",
    "    emin8 = []\n",
    "    emin9 = []\n",
    "    emin10 = []\n",
    "    emin11 = []\n",
    "    emax0 = []\n",
    "    emax1 = []\n",
    "    emax2 = []\n",
    "    emax3 = []\n",
    "    emax4 = []\n",
    "    emax5 = []\n",
    "    emax6 = []\n",
    "    emax7 = []\n",
    "    emax8 = []\n",
    "    emax9 = []\n",
    "    emax10 = []\n",
    "    emax11 = []\n",
    "    dnde0 = []\n",
    "    dnde1 = []\n",
    "    dnde2 = []\n",
    "    dnde3 = []\n",
    "    dnde4 = []\n",
    "    dnde5 = []\n",
    "    dnde6 = []\n",
    "    dnde7 = []\n",
    "    dnde8 = []\n",
    "    dnde9 = []\n",
    "    dnde10 = []\n",
    "    dnde11 = []\n",
    "    dnde_err0 = []\n",
    "    dnde_err1 = []\n",
    "    dnde_err2 = []\n",
    "    dnde_err3 = []\n",
    "    dnde_err4 = []\n",
    "    dnde_err5 = []\n",
    "    dnde_err6 = []\n",
    "    dnde_err7 = []\n",
    "    dnde_err8 = []\n",
    "    dnde_err9 = []\n",
    "    dnde_err10 = []\n",
    "    dnde_err11 = []\n",
    "    index_fit= []\n",
    "    amplitude_fit = []\n",
    "    amplitude_err_fit = []\n",
    "    index_fit = []\n",
    "    index_err_fit = []\n",
    "    reference_fit = []\n",
    "    datasets = Datasets()\n",
    "    \n",
    "    while n_sims < n_obs:\n",
    "        if VERBOSE:\n",
    "            print(f\"\"\"#################### n_sims = {n_sims+1} ####################\"\"\")\n",
    "            for obs_id in obs:\n",
    "                \n",
    "                dataset = maker.run(\n",
    "                    dataset_empty, \n",
    "                    obs_id\n",
    "                )\n",
    "                \n",
    "                dataset = safe_maker.run(\n",
    "                    dataset, \n",
    "                    obs_id\n",
    "                )\n",
    "                \n",
    "                # Energy range maps defined by the mask_safe only\n",
    "                low_energies_safe = dataset.energy_range_safe[0]\n",
    "                \n",
    "                # Energy threshold\n",
    "                energy_threshold = low_energies_safe.get_by_coord({'skycoord': src_position})[0] * low_energies_safe.unit\n",
    "                \n",
    "                # Create spectrum dataseton off from another dataset\n",
    "                dataset_onoff = SpectrumDatasetOnOff.from_spectrum_dataset(\n",
    "                    dataset=dataset, \n",
    "                    acceptance=1, # Relative background efficiency in the on region\n",
    "                    acceptance_off=1./alpha\n",
    "                ) # Relative background efficiency in the off region (alpha = 0.2)\n",
    "                \n",
    "                # Add the model on the dataset\n",
    "                skymodel_fit = skymodel.copy()\n",
    "                dataset_onoff.models = skymodel_fit\n",
    "\n",
    "                # Simulate fake counts (on and off) for the current model and reduced IRFs\n",
    "                try:\n",
    "                    dataset_onoff.fake(\n",
    "                        random_state='random-seed', # Defines random number generator initialisation.\n",
    "                        npred_background=dataset.npred_background() # Predicted background counts\n",
    "                    )\n",
    "                except ValueError as e:\n",
    "                    print(f'DEBUG JPL: In fake: Caught {e}')\n",
    "                    n_failed += 1\n",
    "                    continue\n",
    "                \n",
    "                # append dataset_onoff to the datasets\n",
    "                datasets.append(dataset_onoff)\n",
    "            \n",
    "            #  stack all dataset\n",
    "            dataset_stacked = Datasets(datasets).stack_reduce(name=int(source_name[i]))\n",
    "            \n",
    "            # copy skymodel to fit it\n",
    "            skymodel_fit = skymodel.copy()\n",
    "            \n",
    "            # loads the model into the staked dataset\n",
    "            dataset_stacked.models = skymodel_fit\n",
    "\n",
    "            skymodel_fit.parameters[\"reference\"].quantity = 0.2 * u.TeV\n",
    "            skymodel_fit.parameters[\"amplitude\"].value *= (1.+(2.*np.random.rand(1)-1.)/10.)\n",
    "            skymodel_fit.parameters[\"index\"].value *= (1.+(2.*np.random.rand(1)-1.)/10.)\n",
    "\n",
    "            stacked_fit = Fit(backend=fitbackend, optimize_opts=optimize_opts)\n",
    "            renortet_stacked = stacked_fit.run([dataset_stacked])\n",
    "            print(renortet_stacked.parameters[\"amplitude\"].quantity.value)\n",
    "\n",
    "            amplitude_fit.append(renortet_stacked.parameters[\"amplitude\"].quantity.value)\n",
    "            amplitude_err_fit.append(renortet_stacked.parameters[\"amplitude\"].error)\n",
    "            index_fit.append(renortet_stacked.parameters[\"index\"].quantity.value)\n",
    "            index_err_fit.append(renortet_stacked.parameters[\"index\"].error)\n",
    "            reference_fit.append(renortet_stacked.parameters[\"reference\"].quantity.value)\n",
    "\n",
    "            spectral_model = PowerLawSpectralModel(\n",
    "                amplitude=amplitude[i] * u.Unit('cm^-2 s^-1 MeV^-1'),\n",
    "                reference=1 * u.Unit('MeV'),\n",
    "                index=index[i]\n",
    "            )\n",
    "\n",
    "            absorption_ebl = EBLAbsorptionNormSpectralModel.read_builtin(\"finke\", redshift=red[i])\n",
    "            absspecmodel_ebl = spectral_model * absorption_ebl\n",
    "            \n",
    "            model = SkyModel(spectral_model=absspecmodel_ebl, name=\"crab\")\n",
    "\n",
    "            dataset_stacked.models = [model]\n",
    "            \n",
    "            \n",
    "            # Estimates flux points for a given list of datasets, energies and spectral model\n",
    "            energy_edges = MapAxis.from_energy_bounds(\"0.1 TeV\", \"30 TeV\", nbin=12).edges\n",
    "            fpe = FluxPointsEstimator(energy_edges=energy_edges, source=\"crab\", selection_optional=\"all\")\n",
    "            flux_points = fpe.run(datasets=dataset_stacked)\n",
    "            print(flux_points.to_table(sed_type=\"dnde\", formatted=True))\n",
    "            print(flux_points[\"dnde\"].data)\n",
    "            \n",
    "            # Saves the flux points\n",
    "            file = open(\"/home/bornagain/Documents/GitHub/gammapy/gammapy-notebooks/0.20.1/presentations/gammapy/results/flux_point_src\"+str(int(source_name[i]))+\".txt\",\"+w\")\n",
    "            file.write('E_ref (TeV) E_max (TeV) E_min (TeV) dnde (cm-2 s-1 MeV-1) dnde_err \\r\\n')\n",
    "\n",
    "            for j in range(len(flux_points[\"energy_max\"].value)):\n",
    "                if flux_points[\"dnde\"].data[j] > 0:\n",
    "                    file.write(str(flux_points[\"energy_ref\"].value[j]) + '  ' + str(flux_points[\"energy_max\"].value[j]) + '  ' + str(flux_points[\"energy_min\"].value[j]) + '  ' + str(flux_points[\"dnde\"].data[j])[1:-1] + '  ' + str(flux_points[\"dnde_err\"].data[j])[1:-1] + '\\n')\n",
    "\n",
    "            eref0.append(flux_points[\"energy_ref\"].data[0])\n",
    "            eref1.append(flux_points[\"energy_ref\"].data[1])\n",
    "            eref2.append(flux_points[\"energy_ref\"].data[2])\n",
    "            eref3.append(flux_points[\"energy_ref\"].data[3])\n",
    "            eref4.append(flux_points[\"energy_ref\"].data[4])\n",
    "            eref5.append(flux_points[\"energy_ref\"].data[5])\n",
    "            eref6.append(flux_points[\"energy_ref\"].data[6])\n",
    "            eref7.append(flux_points[\"energy_ref\"].data[7])\n",
    "            eref8.append(flux_points[\"energy_ref\"].data[8])\n",
    "            eref9.append(flux_points[\"energy_ref\"].data[9])\n",
    "            eref10.append(flux_points[\"energy_ref\"].data[10])\n",
    "            eref11.append(flux_points[\"energy_ref\"].data[11])\n",
    "            emin0.append(flux_points[\"energy_min\"].data[0])\n",
    "            emin1.append(flux_points[\"energy_min\"].data[1])\n",
    "            emin2.append(flux_points[\"energy_min\"].data[2])\n",
    "            emin3.append(flux_points[\"energy_min\"].data[3])\n",
    "            emin4.append(flux_points[\"energy_min\"].data[4])\n",
    "            emin5.append(flux_points[\"energy_min\"].data[5])\n",
    "            emin6.append(flux_points[\"energy_min\"].data[6])\n",
    "            emin7.append(flux_points[\"energy_min\"].data[7])\n",
    "            emin8.append(flux_points[\"energy_min\"].data[8])\n",
    "            emin9.append(flux_points[\"energy_min\"].data[9])\n",
    "            emin10.append(flux_points[\"energy_min\"].data[10])\n",
    "            emin11.append(flux_points[\"energy_min\"].data[11])\n",
    "            emax0.append(flux_points[\"energy_max\"].data[0])\n",
    "            emax1.append(flux_points[\"energy_max\"].data[1])\n",
    "            emax2.append(flux_points[\"energy_max\"].data[2])\n",
    "            emax3.append(flux_points[\"energy_max\"].data[3])\n",
    "            emax4.append(flux_points[\"energy_max\"].data[4])\n",
    "            emax5.append(flux_points[\"energy_max\"].data[5])\n",
    "            emax6.append(flux_points[\"energy_max\"].data[6])\n",
    "            emax7.append(flux_points[\"energy_max\"].data[7])\n",
    "            emax8.append(flux_points[\"energy_max\"].data[8])\n",
    "            emax9.append(flux_points[\"energy_max\"].data[9])\n",
    "            emax10.append(flux_points[\"energy_max\"].data[10])\n",
    "            emax11.append(flux_points[\"energy_max\"].data[11])\n",
    "            dnde0.append(flux_points[\"dnde\"].data[0])\n",
    "            dnde1.append(flux_points[\"dnde\"].data[1])\n",
    "            dnde2.append(flux_points[\"dnde\"].data[2])\n",
    "            dnde3.append(flux_points[\"dnde\"].data[3])\n",
    "            dnde4.append(flux_points[\"dnde\"].data[4])\n",
    "            dnde5.append(flux_points[\"dnde\"].data[5])\n",
    "            dnde6.append(flux_points[\"dnde\"].data[6])\n",
    "            dnde7.append(flux_points[\"dnde\"].data[7])\n",
    "            dnde8.append(flux_points[\"dnde\"].data[8])\n",
    "            dnde9.append(flux_points[\"dnde\"].data[9])\n",
    "            dnde10.append(flux_points[\"dnde\"].data[10])\n",
    "            dnde11.append(flux_points[\"dnde\"].data[11])\n",
    "            dnde_err0.append(flux_points[\"dnde_err\"].data[0])\n",
    "            dnde_err1.append(flux_points[\"dnde_err\"].data[1])\n",
    "            dnde_err2.append(flux_points[\"dnde_err\"].data[2])\n",
    "            dnde_err3.append(flux_points[\"dnde_err\"].data[3])\n",
    "            dnde_err4.append(flux_points[\"dnde_err\"].data[4])\n",
    "            dnde_err5.append(flux_points[\"dnde_err\"].data[5])\n",
    "            dnde_err6.append(flux_points[\"dnde_err\"].data[6])\n",
    "            dnde_err7.append(flux_points[\"dnde_err\"].data[7])\n",
    "            dnde_err8.append(flux_points[\"dnde_err\"].data[8])\n",
    "            dnde_err9.append(flux_points[\"dnde_err\"].data[9])\n",
    "            dnde_err10.append(flux_points[\"dnde_err\"].data[10])\n",
    "            dnde_err11.append(flux_points[\"dnde_err\"].data[11])\n",
    "            \n",
    "            # Extract analysis statistics\n",
    "            significancee = WStatCountsStatistic(n_on=sum(dataset_stacked.counts.data), n_off=sum(dataset_stacked.counts_off.data), alpha=0.2).sqrt_ts\n",
    "            significance.append(significancee)\n",
    " \n",
    "            n_sims += 1\n",
    "            print(np.median(significance))\n",
    "\n",
    "    output['Source_Name'].append(int(source_name[i]))\n",
    "    output['RA_pointing'].append(pointing.ra.value)\n",
    "    output['DEC_pointing'].append(pointing.dec.value)\n",
    "    output['RAJ2000'].append(src_position.ra.value)\n",
    "    output['DEJ2000'].append(src_position.dec.value)\n",
    "    output['Redshift'].append(absorption.redshift.value)\n",
    "    output['Amplitude'].append(specmodel.amplitude.value)\n",
    "    output['Luminosity'].append(luminosity[i])\n",
    "    output['Offset'].append(offset[i])\n",
    "    output['Index'].append(specmodel.index.value)\n",
    "    output['Site'].append(sites)\n",
    "    output['Irf_Zen_pointing'].append(int(IRF_zen[i]))\n",
    "    output['Irf_Time'].append(float(irftime.split('h')[0]))\n",
    "    output['Ethreshold'].append(energy_threshold.value)\n",
    "    output['AboveEthFlag'].append(AboveEthFlag)\n",
    "    output['N_sims'].append(n_sims)\n",
    "    output['N_failed'].append(n_failed)\n",
    "    output['Significance'].append(np.median(significance))\n",
    "    output['eref0'].append(eref0)\n",
    "    output['eref1'].append(eref1)\n",
    "    output['eref2'].append(eref2)\n",
    "    output['eref3'].append(eref3)\n",
    "    output['eref4'].append(eref4)\n",
    "    output['eref5'].append(eref5)\n",
    "    output['eref6'].append(eref6)\n",
    "    output['eref7'].append(eref7)\n",
    "    output['eref8'].append(eref8)\n",
    "    output['eref9'].append(eref9)\n",
    "    output['eref10'].append(eref10)\n",
    "    output['eref11'].append(eref11)\n",
    "    output['emin0'].append(emin0)\n",
    "    output['emin1'].append(emin1)\n",
    "    output['emin2'].append(emin2)\n",
    "    output['emin3'].append(emin3)\n",
    "    output['emin4'].append(emin4)\n",
    "    output['emin5'].append(emin5)\n",
    "    output['emin6'].append(emin6)\n",
    "    output['emin7'].append(emin7)\n",
    "    output['emin8'].append(emin8)\n",
    "    output['emin9'].append(emin9)\n",
    "    output['emin10'].append(emin10)\n",
    "    output['emin11'].append(emin11)\n",
    "    output['emax0'].append(emax0)\n",
    "    output['emax1'].append(emax1)\n",
    "    output['emax2'].append(emax2)\n",
    "    output['emax3'].append(emax3)\n",
    "    output['emax4'].append(emax4)\n",
    "    output['emax5'].append(emax5)\n",
    "    output['emax6'].append(emax6)\n",
    "    output['emax7'].append(emax7)\n",
    "    output['emax8'].append(emax8)\n",
    "    output['emax9'].append(emax9)\n",
    "    output['emax10'].append(emax10)\n",
    "    output['emax11'].append(emax11)\n",
    "    output['dnde0'].append(dnde0)\n",
    "    output['dnde1'].append(dnde1)\n",
    "    output['dnde2'].append(dnde2)\n",
    "    output['dnde3'].append(dnde3)\n",
    "    output['dnde4'].append(dnde4)\n",
    "    output['dnde5'].append(dnde5)\n",
    "    output['dnde6'].append(dnde6)\n",
    "    output['dnde7'].append(dnde7)\n",
    "    output['dnde8'].append(dnde8)\n",
    "    output['dnde9'].append(dnde9)\n",
    "    output['dnde10'].append(dnde10)\n",
    "    output['dnde11'].append(dnde11)\n",
    "    output['dnde_err0'].append(dnde_err0)\n",
    "    output['dnde_err1'].append(dnde_err1)\n",
    "    output['dnde_err2'].append(dnde_err2)\n",
    "    output['dnde_err3'].append(dnde_err3)\n",
    "    output['dnde_err4'].append(dnde_err4)\n",
    "    output['dnde_err5'].append(dnde_err5)\n",
    "    output['dnde_err6'].append(dnde_err6)\n",
    "    output['dnde_err7'].append(dnde_err7)\n",
    "    output['dnde_err8'].append(dnde_err8)\n",
    "    output['dnde_err9'].append(dnde_err9)\n",
    "    output['dnde_err10'].append(dnde_err10)\n",
    "    output['dnde_err11'].append(dnde_err11)\n",
    "    output['amplitude_fit'].append(amplitude_fit)\n",
    "    output['amplitude_err_fit'].append(amplitude_err_fit)\n",
    "    output['index_fit'].append(index_fit)\n",
    "    output['index_err_fit'].append(index_err_fit)\n",
    "    output['reference_fit'].append(reference_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48222f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save renortets\n",
    "renortets = Table()\n",
    "renortets['Source_Name'] = Column(output['Source_Name'], description='Source name')\n",
    "renortets['RA_pointing'] = Column(output['RA_pointing'], format='{:.6f}', unit='degree', description='Right Ascension')\n",
    "renortets['DEC_pointing'] = Column(output['DEC_pointing'], format='{:.6f}', unit='degree', description='Declination')\n",
    "renortets['RAJ2000'] = Column(output['RAJ2000'], format='{:.6f}', unit='degree', description='Right Ascension')\n",
    "renortets['DEJ2000'] = Column(output['DEJ2000'], format='{:.6f}', unit='degree', description='Declination')\n",
    "renortets['Redshift'] = Column(output['Redshift'], format='{:.4f}', unit=None, description='Redshift')\n",
    "renortets['Amplitude'] = Column(output['Amplitude'], format='{:.4f}', unit=None, description='Amplitude')\n",
    "renortets['Index'] = Column(output['Index'], format='{:.4f}', unit=None, description='Index')\n",
    "renortets['Luminosity'] = Column(output['Luminosity'], format='{:.4f}', unit=None, description='Luminosity')\n",
    "renortets['Offset'] = Column(output['Offset'], format='{:.6f}', unit=None, description='Offset')\n",
    "renortets['Site'] = Column(output['Site'], description='Site of the considered CTA array')\n",
    "renortets['Ethreshold'] = Column(output['Ethreshold'], unit='TeV', description='Effective energy threshold')\n",
    "renortets['EthFlag'] = Column(output['AboveEthFlag'], unit=None, description='Is requested minimal energy high enough, i.e. above energy threshold from IRF ?')\n",
    "renortets['N_sims'] = Column(output['N_sims'], unit=None, description='Number of successfully thrown simulations')\n",
    "renortets['N_failed'] = Column(output['N_failed'], unit=None, description='Number of failed simulations')\n",
    "renortets['Irf_Zen_pointing'] = Column(output['Irf_Zen_pointing'], unit='deg', description='Irf_Zen_pointing')\n",
    "renortets['Significance'] = Column(output['Significance'], format='{:.2f}', unit='', description='Median significance')\n",
    "renortets['eref0'] = Column(output['eref0'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref1'] = Column(output['eref1'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref2'] = Column(output['eref2'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref3'] = Column(output['eref3'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref4'] = Column(output['eref4'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref5'] = Column(output['eref5'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref6'] = Column(output['eref6'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref7'] = Column(output['eref7'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref8'] = Column(output['eref8'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref9'] = Column(output['eref9'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref10'] = Column(output['eref10'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['eref11'] = Column(output['eref11'], format='{:.2f}', unit='', description='eref')\n",
    "renortets['emax0'] = Column(output['emax0'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax1'] = Column(output['emax1'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax2'] = Column(output['emax2'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax3'] = Column(output['emax3'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax4'] = Column(output['emax4'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax5'] = Column(output['emax5'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax6'] = Column(output['emax6'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax7'] = Column(output['emax7'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax8'] = Column(output['emax8'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax9'] = Column(output['emax9'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax10'] = Column(output['emax10'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emax11'] = Column(output['emax11'], format='{:.2f}', unit='', description='emax')\n",
    "renortets['emin0'] = Column(output['emin0'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin1'] = Column(output['emin1'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin2'] = Column(output['emin2'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin3'] = Column(output['emin3'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin4'] = Column(output['emin4'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin5'] = Column(output['emin5'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin6'] = Column(output['emin6'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin7'] = Column(output['emin7'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin8'] = Column(output['emin8'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin9'] = Column(output['emin9'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin10'] = Column(output['emin10'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['emin11'] = Column(output['emin11'], format='{:.2f}', unit='', description='emin')\n",
    "renortets['dnde0'] = Column(output['dnde0'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde1'] = Column(output['dnde1'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde2'] = Column(output['dnde2'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde3'] = Column(output['dnde3'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde4'] = Column(output['dnde4'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde5'] = Column(output['dnde5'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde6'] = Column(output['dnde6'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde7'] = Column(output['dnde7'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde8'] = Column(output['dnde8'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde9'] = Column(output['dnde9'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde10'] = Column(output['dnde10'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde11'] = Column(output['dnde11'], format='{:.2f}', unit='', description='dnde')\n",
    "renortets['dnde_err0'] = Column(output['dnde_err0'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err1'] = Column(output['dnde_err1'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err2'] = Column(output['dnde_err2'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err3'] = Column(output['dnde_err3'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err4'] = Column(output['dnde_err4'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err5'] = Column(output['dnde_err5'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err6'] = Column(output['dnde_err6'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err7'] = Column(output['dnde_err7'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err8'] = Column(output['dnde_err8'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err9'] = Column(output['dnde_err9'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err10'] = Column(output['dnde_err10'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['dnde_err11'] = Column(output['dnde_err11'], format='{:.2f}', unit='', description='dnde_err')\n",
    "renortets['amplitude_fit'] = Column(output['amplitude_fit'], format='{:.2f}', unit='', description='amplitude_fit')\n",
    "renortets['amplitude_err_fit'] = Column(output['amplitude_err_fit'], format='{:.2f}', unit='', description='amplitude_err_fit')\n",
    "renortets['index_fit'] = Column(output['index_fit'], format='{:.2f}', unit='', description='index_fit')\n",
    "renortets['index_err_fit'] = Column(output['index_err_fit'], format='{:.2f}', unit='', description='index_err_fit')\n",
    "renortets['reference_fit'] = Column(output['reference_fit'], format='{:.2f}', unit='', description='reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae8b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "renortets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcbffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"/home/bornagain/Documents/GitHub/gammapy/gammapy-notebooks/0.20.1/presentations/gammapy/results/North_PL_D11_1x.txt\",\"+w\")\n",
    "file.write('Source_Name  RA  DEC  Redshift  Luminosity  Index  Amplitude  E_th  Significance  \\r\\n')\n",
    "\n",
    "for i in range(len(renortets['RAJ2000'])):\n",
    "    file.write(str(int(source_name[i])) + '  ' + str(renortets['RAJ2000'][i]) + '  ' + str(renortets['DEJ2000'][i]) + '  ' + str(renortets['Redshift'][i]) + '  ' + str(renortets['Luminosity'][i]) + '  ' + str(renortets['Index'][i]) + '  ' + str(renortets['Amplitude'][i]) + '  ' + str(renortets['Ethreshold'][i]) + '  ' + str(renortets['Significance'][i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3fb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.read_csv('results/North_PL_D11_1x.txt', sep='  ', engine='python')\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe4f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(selected_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f98d8",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315ad52",
   "metadata": {},
   "source": [
    "üîù [Back to Top](#intro)<br>"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
