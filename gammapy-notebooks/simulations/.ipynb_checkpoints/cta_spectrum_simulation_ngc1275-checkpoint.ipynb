{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFRH-pyI6rkW"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/me-manu/gammaALPs/blob/master/docs/tutorials/cta_spectrum_simulation_ngc1275.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eAe8JT-6mtC6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HUgeuuQxmtC9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patheffects import withStroke\n",
    "from astropy import constants as c\n",
    "from scipy.integrate import simpson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xD09DhSmtC9",
    "tags": []
   },
   "source": [
    "\n",
    "# Simulating NGC 1275 with and without axion-like particles\n",
    "\n",
    "First we will simulate photon-survival probabilities for the propagation from NGC1275 inside the Perseus cluster towards Earch. Secondly, we will simulate a CTA observation of NGC1275 without ALPs and fit this simulation with our ALP modified spectra.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- installed `gammapy`, version 1.0.1, see https://docs.gammapy.org/1.0/index.html\n",
    "- installed `gammaALPs` version 0.3, see https://gammaalps.readthedocs.io/en/latest/ (will also be done below)\n",
    "- CTA IRFs available. We will use the CTA North IRFs for 20 degree zenith observation with backgrounds optimized for 5 hour observations. The IRFs are available here: https://zenodo.org/record/5499840#.YUya5WYzbUI\n",
    "\n",
    "## Further information\n",
    "\n",
    "This hands-on sesssion roughly follows the tutorials given here:\n",
    "- https://docs.gammapy.org/1.0/tutorials/analysis-1d/spectrum_simulation.html\n",
    "- https://docs.gammapy.org/1.0/tutorials/analysis-1d/spectral_analysis.html\n",
    "- https://gammaalps.readthedocs.io/en/latest/tutorials/mixing_ICM_Gaussian_Turbulence.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-N5Ooubm6k1"
   },
   "source": [
    "### Installing `gammapy` from within notebook\n",
    "\n",
    "If you haven't installed gammapy yet, you can run the following command. If you are working in your machine and not on google colab, I strongly advice that you set up a new conda environment and not simply run `pip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WBrTEGoLnBjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gammapy==1.0.1\n",
      "  Downloading gammapy-1.0.1.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (8.1.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (6.0)\n",
      "Requirement already satisfied: regions>=0.5.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (0.6)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (3.6.2)\n",
      "Requirement already satisfied: scipy!=1.10,>=1.4 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (1.9.1)\n",
      "Requirement already satisfied: pydantic>=1.4 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (1.23.5)\n",
      "Requirement already satisfied: iminuit>=2.8.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (2.17.0)\n",
      "Requirement already satisfied: astropy>=5.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from gammapy==1.0.1) (5.1.1)\n",
      "Requirement already satisfied: packaging>=19.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from astropy>=5.0->gammapy==1.0.1) (22.0)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from astropy>=5.0->gammapy==1.0.1) (2.0.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from matplotlib>=3.4->gammapy==1.0.1) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from pydantic>=1.4->gammapy==1.0.1) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/gamma/anaconda3/envs/gammapy-1.0/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->gammapy==1.0.1) (1.16.0)\n",
      "Building wheels for collected packages: gammapy\n",
      "  Building wheel for gammapy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gammapy: filename=gammapy-1.0.1-cp39-cp39-linux_x86_64.whl size=819264 sha256=218e59120e07e283730072826204c786ea23d4f85b9d5ad1da0a4ab2e2168112\n",
      "  Stored in directory: /home/gamma/.cache/pip/wheels/bb/57/a5/2bb0cccb311407c47fd42b5a31c7987cb976f41ca6c2266fee\n",
      "Successfully built gammapy\n",
      "Installing collected packages: gammapy\n",
      "  Attempting uninstall: gammapy\n",
      "    Found existing installation: gammapy 1.0\n",
      "    Uninstalling gammapy-1.0:\n",
      "      Successfully uninstalled gammapy-1.0\n",
      "Successfully installed gammapy-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gammapy==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImROqoZbq72A"
   },
   "source": [
    "### Downloading CTA IRFs\n",
    "\n",
    "If you haven't downloaded the IRFs yet, you can simply run the command below in google colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHdODHMypVqw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-29 17:11:40--  https://zenodo.org/record/5499840/files/cta-prod5-zenodo-fitsonly-v0.1.zip\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44065624 (42M) [application/octet-stream]\n",
      "Saving to: ‘cta-prod5-zenodo-fitsonly-v0.1.zip’\n",
      "\n",
      "od5-zenodo-fitsonly  63%[===========>        ]  26,87M   872KB/s    eta 48s    "
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/5499840/files/cta-prod5-zenodo-fitsonly-v0.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQuuLj8urXhq"
   },
   "source": [
    "Then you can unzip the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4gpQSpVrPio"
   },
   "outputs": [],
   "source": [
    "!unzip cta-prod5-zenodo-fitsonly-v0.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdngdTkUrbNz"
   },
   "source": [
    "And look at the contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r93EqbxurgJU"
   },
   "outputs": [],
   "source": [
    "!ls fits/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOKJn7-HtXQ_"
   },
   "source": [
    "We will work with the CTA North IRFs for 20 degree zenith observations. So we have to untar the corresponding file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "844_zjMVrmhY"
   },
   "outputs": [],
   "source": [
    "!tar -xzvf fits/CTA-Performance-prod5-v0.1-North-20deg.FITS.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFSkWCA6r2tM"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI4Q2B94mtC_"
   },
   "source": [
    "## Installing `gammaALPs`\n",
    "\n",
    "We assume that `gammapy` version 1.0.1 is already installed and this notebook runs with the corresponding kernel. If not already installed, the `gammaALPs` package can be installed with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1gG2TFumtC_"
   },
   "outputs": [],
   "source": [
    "!pip install gammaALPs==0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjXtFDVumtDA"
   },
   "source": [
    "## Calculating the photon survival probabilities\n",
    "\n",
    "First, we calculate the survival probabilities $P_{\\gamma\\to\\gamma}$ for mixing inside the Perseus cluster and in the magnetic field of the milky way. We will also include absorption by the EBL. The modelling of the cluster magnetic field follows Ajello et al. (2016) (https://arxiv.org/abs/1603.06978) where the $B$ field is modelled as a field with Gaussian turbulence. \n",
    "\n",
    "First, we need some imports from `gammaALPs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEd13T9lmtDA"
   },
   "outputs": [],
   "source": [
    "from gammaALPs.core import Source, ALP, ModuleList\n",
    "from gammaALPs.base import environs, transfer\n",
    "from ebltable.tau_from_model import OptDepth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCxP63_hmtDB"
   },
   "source": [
    "And initialize an ALP object, which stores the ALP mass $m_a$ (in neV) and the coupling $g_{a\\gamma}$ (in $10^{-11}\\mathrm{GeV}^{-1}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ584PaGmtDC"
   },
   "outputs": [],
   "source": [
    "m, g = 1.,1.\n",
    "alp = ALP(m,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tAGUYhumtDC"
   },
   "source": [
    "Next, we set the source properties (redshift and sky coordinates) in the ```Source``` container. These can be taken form your favorite catalot for extragalactic objects, e.g., <a href=\"http://ned.ipac.caltech.edu/\">NED</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaH0oFHZmtDC"
   },
   "outputs": [],
   "source": [
    "ngc1275 = Source(z=0.017559, ra='03h19m48.1s', dec='+41d30m42s')\n",
    "print (ngc1275.z)\n",
    "print (ngc1275.ra, ngc1275.dec)\n",
    "print (ngc1275.l, ngc1275.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "La7TLlE6mtDD"
   },
   "source": [
    "### Init the module list\n",
    "\n",
    "Next, we can initialize the list of transfer modules that will store the different magnetic field environments. \n",
    "First, we provide the energies for which we would like to compute the conversion probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqDlV9DkmtDD"
   },
   "outputs": [],
   "source": [
    "EGeV = np.logspace(1.5, 4.5, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8SgiY-8mtDD"
   },
   "source": [
    "pin = np.diag((1.,1.,0.)) * 0.5Now initialize the initial photon polarization. Since we are dealing with a gamma-ray source, no ALPs are initially present in the beam (third diagonal element is zero). The polarization density matrix is normalized such that its trace is equal to one, $\\mathrm{Tr}(\\rho_\\mathrm{in}) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YgNvnfZmtDE"
   },
   "outputs": [],
   "source": [
    "pin = np.diag((1.,1.,0.)) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltDt83-LmtDE"
   },
   "source": [
    "The module list is initialized with our choices for the ALP, our source, the initial polarization, and the energies at which we compute the photon-ALP mixingm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6L7X4r-mtDE"
   },
   "outputs": [],
   "source": [
    "ml = ModuleList(alp, ngc1275, pin = pin, EGeV = EGeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD9n8RTsmtDE"
   },
   "source": [
    "Now, we add the different environments to the module list. For the EBL, we will use the model from [Dominguez et al. (2011)](https://ui.adsabs.harvard.edu/abs/2011MNRAS.410.2556D/abstract). The other parameters are the same in [Ajello et al. 2016](https://arxiv.org/abs/1603.06978). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tqoSgfBmtDE"
   },
   "outputs": [],
   "source": [
    "ml.add_propagation(\"ICMGaussTurb\", \n",
    "                  0, # position of module counted from the source. \n",
    "                  nsim=100, # number of random B-field realizations\n",
    "                  B0=10.,  # rms of B field in muG\n",
    "                  n0=3.9e-2,  # normalization of electron density in cm-3\n",
    "                  n2=4.05e-3, # second normalization of electron density, see Churazov et al. 2003, Eq. 4 on cm-3\n",
    "                  r_abell=500., # extension of the cluster in kpc\n",
    "                  r_core=80.,   # electron density parameter, see Churazov et al. 2003, Eq. 4 in kpc\n",
    "                  r_core2=280., # electron density parameter, see Churazov et al. 2003, Eq. 4 in kpc\n",
    "                  beta=1.2,  # electron density parameter, see Churazov et al. 2003, Eq. 4\n",
    "                  beta2=0.58, # electron density parameter, see Churazov et al. 2003, Eq. 4\n",
    "                  eta=0.5, # scaling of B-field with electron denstiy\n",
    "                  kL=0.18, # maximum turbulence scale in kpc^-1, taken from A2199 cool-core cluster, see Vacca et al. 2012 \n",
    "                  kH=9.,  # minimum turbulence scale, taken from A2199 cool-core cluster, see Vacca et al. 2012\n",
    "                  q=-2.80, # turbulence spectral index, taken from A2199 cool-core cluster, see Vacca et al. 2012\n",
    "                  seed=0 # random seed for reproducability, set to None for random seed.\n",
    "                 )\n",
    "ml.add_propagation(\"EBL\",1, eblmodel='dominguez') # EBL attenuation comes second, after beam has left cluster\n",
    "ml.add_propagation(\"GMF\",2, model='jansson12') # finally, the beam enters the Milky Way Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59Ajc9xZmtDF"
   },
   "source": [
    "List the module names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZuWf4x6mtDF"
   },
   "outputs": [],
   "source": [
    "print(ml.modules.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EctoMauVmtDF"
   },
   "source": [
    "We can also inspect the magnetic-field realization and electron density along the line of sight. The magnetic-field realizations are stored in `ml.modules[\"ICMGaussTurb\"].Bn`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrZ-lP6vmtDF"
   },
   "outputs": [],
   "source": [
    "print (ml.modules[\"ICMGaussTurb\"].Bn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-AvqDl8mtDF"
   },
   "source": [
    "And multiplying the magnetic field with the $\\psi$ angles stored in `ml.modules[\"ICMGaussTurb\"].Psin` will give us the two components transversal to the propagation direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpFipaDqmtDF"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for i, B in enumerate(ml.modules[\"ICMGaussTurb\"].Bn):\n",
    "    ax1.plot(ml.modules[\"ICMGaussTurb\"].r,\n",
    "             B * np.sin(ml.modules[\"ICMGaussTurb\"].psin[i]),\n",
    "             lw=1 if not i else 0.1,\n",
    "             alpha=1 if not i else 0.1,\n",
    "             color=plt.cm.tab10(0.)\n",
    "            )\n",
    "    ax2.plot(ml.modules[\"ICMGaussTurb\"].r,\n",
    "             B * np.cos(ml.modules[\"ICMGaussTurb\"].psin[i]),\n",
    "             lw=1 if not i else 0.1,\n",
    "             alpha=1 if not i else 0.1,\n",
    "             color=plt.cm.tab10(0.1)\n",
    "            ) \n",
    "    \n",
    "ax1.set_ylabel('$B$ field ($\\mu$G)')\n",
    "ax1.set_xlabel('$r$ (kpc)')\n",
    "ax2.set_xlabel('$r$ (kpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLLw18obmtDG"
   },
   "source": [
    "The coherent magnetic field in the Milky Way used in the mixing can be plotted in a similar way. Note that we're using the attributes `ml.modules[\"GMF\"].B` and `ml.modules[\"GMF\"].psi` since we are dealing with one coherent magnetic field and not many random realizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrLvL8T4mtDG"
   },
   "outputs": [],
   "source": [
    "plt.plot(ml.modules[\"GMF\"].r, ml.modules[\"GMF\"].B * np.sin(ml.modules[\"GMF\"].psi),\n",
    "         lw=2)\n",
    "plt.plot(ml.modules[\"GMF\"].r, ml.modules[\"GMF\"].B * np.cos(ml.modules[\"GMF\"].psi),\n",
    "         lw=2) \n",
    "plt.ylabel('$B$ field ($\\mu$G)')\n",
    "plt.xlabel('$r$ (kpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzVFTbnMmtDG"
   },
   "source": [
    "The electron density in our Perseus cluster model looks like this (and comes from [Churazov et al., 2003](https://ui.adsabs.harvard.edu/abs/2003ApJ...590..225C/abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlUDNrkamtDG"
   },
   "outputs": [],
   "source": [
    "plt.loglog(ml.modules[\"ICMGaussTurb\"].r, ml.modules[\"ICMGaussTurb\"].nel)\n",
    "plt.ylabel('$n_\\mathrm{el}$ (cm$^{-3}$)')\n",
    "plt.xlabel('$r$ (kpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVg1txwdmtDG"
   },
   "source": [
    "### Spatial correlation and coherence length\n",
    "\n",
    "The `gammaALPs.bfields.Bgaussian` class has methods to calculate the spatial correlation of the magnetic field and the rotation measure. We can access these methods through the the magnetic field model mehtod, which we can access through `ml.modules['ICMGaussTurb'].Bfield_model`. \n",
    "\n",
    "The spatial correlation $C(x_3) = \\langle B_\\perp(\\vec{x}) B_\\perp(\\vec{x} + x_3 \\vec{e}_3)\\rangle$ of the transversal magnetic field along the line of sight $z$ is computed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFeuVufimtDG"
   },
   "outputs": [],
   "source": [
    "x3 = np.linspace(0.,50.,1000)  # distance in kpc from cluster center\n",
    "c = ml.modules[\"ICMGaussTurb\"].Bfield_model.spatial_correlation(x3) \n",
    "\n",
    "plt.plot(x3, c / c[0])\n",
    "plt.xlabel(\"$z$ (kpc)\")\n",
    "plt.ylabel(\"$C(z) / C(0)$\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re7k9wsAmtDG"
   },
   "source": [
    "This is turn can be used to calculate the coherence length of the field, \n",
    "$$ \\Lambda_C = \\frac{1}{C(0)} \\int\\limits_0^\\infty C(z)dz. $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDS7JrqbmtDG"
   },
   "outputs": [],
   "source": [
    "z = np.linspace(0.,1e3,1000)  # distance in kpc from cluster center\n",
    "c = ml.modules[\"ICMGaussTurb\"].Bfield_model.spatial_correlation(z) \n",
    "\n",
    "Lambda_c = simpson(c, z) / c[0]\n",
    "\n",
    "print (\"Coherence length of the field is Lambda_C = {0:.3e} kpc\".format(Lambda_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHqOKHyrmtDH"
   },
   "source": [
    "### Run all modules\n",
    "\n",
    "Now we run the modules. \n",
    "\n",
    "The ```px, py, pa``` variables contain the mixing probability into the two photon polarization states ($x$, $y$) and into the axion state ($a$). If this is taking too much time, consider reducing the number of energies and / or the number of simulated $B$-field realizations. On my laptop, 100 realizations at 150 energies take around 30s. On google colab, it took around 2 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOhwkRQcmtDH"
   },
   "source": [
    "We can also change the ALP parameters before running the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aiye9PZJmtDH"
   },
   "outputs": [],
   "source": [
    "ml.alp.m = 30.\n",
    "ml.alp.g = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Bb15o6mtDH"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "px, py, pa = ml.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7366-CeomtDH"
   },
   "source": [
    "### Plot the output \n",
    "\n",
    "We now plot the resulting total survival probability, $P_{\\gamma\\gamma} = P_x + P_y$ for each \n",
    "magnetic-field realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_8puUV7mtDH"
   },
   "outputs": [],
   "source": [
    "pgg = px + py # the total photon survival probability\n",
    "\n",
    "effect = dict(path_effects=[withStroke(foreground=\"w\", linewidth=2)])\n",
    "\n",
    "for i, p in enumerate(pgg):  # plot all realizations\n",
    "    plt.loglog(ml.EGeV, p, color=\"C0\",\n",
    "               alpha=1 if not i else 0.2,\n",
    "               lw=1 if not i else 0.1)\n",
    "    \n",
    "# plot the EBL case only\n",
    "atten = np.exp(-ml.modules['OptDepth'].opt_depth(ml.source.z, ml.EGeV / 1e3))\n",
    "plt.loglog(ml.EGeV, atten, ls='--', color=\"C1\")\n",
    "\n",
    "\n",
    "plt.xlabel('Energy (GeV)')\n",
    "plt.ylabel('Photon survival probability')\n",
    "\n",
    "plt.annotate(r'$m_a = {0:.1f}\\,\\mathrm{{neV}}, g_{{a\\gamma}}'\n",
    "             r' = {1:.1f} \\times 10^{{-11}}\\,\\mathrm{{GeV}}^{{-1}}$'.format(ml.alp.m, ml.alp.g),\n",
    "             xy=(0.05,0.1), \n",
    "             size ='x-large',\n",
    "             xycoords='axes fraction',\n",
    "             **effect)\n",
    "\n",
    "plt.ylim(1e-1, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsCUonRRmtDH"
   },
   "source": [
    "### Questions:\n",
    "\n",
    "- how does $P_{\\gamma\\to\\gamma}$ change for different ALP masses / couplings? You may want to change one parameter at a time and simulate this for less B-field realizations. \n",
    "- how does the $B$-field correlation length and $P_{\\gamma\\to\\gamma}$ change for different $k_{L/H}$ and power-law index $q$ and rms field strength $B$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhnGog_zmtDI"
   },
   "source": [
    "## `Gammapy` simulations\n",
    "\n",
    "Now that we have our theoretical predictions for the photon propagation with ALPs (stored in the `pgg` array) and without ALPs (EBL only case stored in the `atten` array), we can setup and run the `gammapy` simulation.\n",
    "\n",
    "First we need some additional imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9EeBjCBmtDI",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "from regions import CircleSkyRegion\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C0R7VP2mtDI"
   },
   "source": [
    "And more imports from `gammapy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xp4Rx6VEmtDI",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gammapy.data import Observation, observatory_locations\n",
    "from gammapy.datasets import SpectrumDataset, SpectrumDatasetOnOff\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.makers import SpectrumDatasetMaker\n",
    "from gammapy.maps import MapAxis, RegionGeom\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling import models \n",
    "from gammapy.estimators import FluxPointsEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7fNAKtemtDI"
   },
   "source": [
    "## Simulation of a single spectrum\n",
    "\n",
    "To do a simulation, we need to define the observational parameters like\n",
    "the livetime, the offset, the assumed integration radius, the energy\n",
    "range to perform the simulation for and the choice of spectral model. We\n",
    "then use an in-memory observation which is convolved with the IRFs to\n",
    "get the predicted number of counts. This is Poission fluctuated using\n",
    "the `fake()` to get the simulated counts for each observation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhu7u5iMmtDI",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define simulation parameters parameters\n",
    "livetime = 5. * u.h\n",
    "\n",
    "pointing = SkyCoord(ml.source.ra, ml.source.dec, unit=\"deg\", frame=\"fk5\")\n",
    "offset = 0.5 * u.deg\n",
    "\n",
    "# Reconstructed and true energy axis\n",
    "energy_axis = MapAxis.from_edges(\n",
    "    np.logspace(-1, 1.5, 26), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "\n",
    "energy_axis_true = MapAxis.from_edges(\n",
    "    np.logspace(-1.5, 2.0, 71), unit=\"TeV\", name=\"energy_true\", interp=\"log\"\n",
    ")\n",
    "\n",
    "on_region_radius = Angle(\"0.11 deg\")\n",
    "\n",
    "center = pointing.directional_offset_by(position_angle=0 * u.deg, separation=offset)\n",
    "on_region = CircleSkyRegion(center=center, radius=on_region_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hkgScKRmtDI"
   },
   "source": [
    "Now we define the intrinsic source model. This is taken from the VERITAS observation of NGC1275 during a flaring episode. During the observation, the source could be described with a power law with exponential cutoff, \n",
    "\n",
    "$$ \\phi(E) = N_0 \\left(\\frac{E}{E_0}\\right)^{-\\Gamma}\\exp\\left(-\\frac{E}{E_\\mathrm{cut}}\\right) $$\n",
    "\n",
    "with $N_0 = 1.54\\times10^{-9}\\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}\\,\\mathrm{TeV}^{-1}$, $\\Gamma = 2.11$, $E_\\mathrm{cut} = 0.54\\,$TeV, and $E_0 = 0.3\\,$TeV.\n",
    "\n",
    "Go to the available spectral models here: https://docs.gammapy.org/1.0/user-guide/model-gallery/index.html \n",
    "and implement the correct spectrum. Note that the `gammapy` implementation uses $\\lambda = E_\\mathrm{cut}^{-1}$ for the fitting. Also note that the parameters need to set with the correct units (using the `astropy` implementation). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ7HgfkamtDI"
   },
   "outputs": [],
   "source": [
    "model_intrinsic = models.ExpCutoffPowerLawSpectralModel(\n",
    "    index=2.11,\n",
    "    amplitude=1.54e-9 * u.Unit(\"cm-2 s-1 TeV-1\"),\n",
    "    lambda_=1. / 0.54 / u.TeV,\n",
    "    reference=0.3 * u.TeV,\n",
    ")\n",
    "print(model_intrinsic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWO1PuipmtDI"
   },
   "source": [
    "With the intrinsic model, we now build a compound model, which multiplies the intrinsic model with a template model that includes the EBL absorption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jU73fVQgmtDI"
   },
   "outputs": [],
   "source": [
    "# EBL absorption template\n",
    "ebl_absorption = models.TemplateSpectralModel(ml.EGeV * u.GeV, atten)\n",
    "\n",
    "# Compound model\n",
    "model_input = models.CompoundSpectralModel(model_intrinsic, ebl_absorption, operator=operator.mul)\n",
    "print(model_input)\n",
    "\n",
    "# and the Skymodel\n",
    "model_no_alps = models.SkyModel(spectral_model=model_intrinsic, name=\"ngc1275\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhCxLVIzmtDJ"
   },
   "source": [
    "Let's plot the intrinsic and observed models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFjUiWPvmtDJ"
   },
   "outputs": [],
   "source": [
    "ax = model_intrinsic.plot(energy_bounds=[0.1, 30.] * u.TeV, energy_power=2, ls='--')\n",
    "_ = model_input.plot(energy_bounds=[0.1, 30.] * u.TeV, energy_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8K4OF_WmtDJ"
   },
   "source": [
    "We see that the EBL absorption is almost negligible due to the small value of the redshift. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2yNR3jfmtDJ"
   },
   "source": [
    "### Load the instrumental response function\n",
    "\n",
    "You should have downloaded and unpacked the CTA response functions, which are available here: https://zenodo.org/record/5499840\n",
    "\n",
    "\n",
    "In the cell below, you need to set the correct path with the IRF for 20 deg zenith and 5 hours observation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0mgLPA0mtDJ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "irfs = load_cta_irfs(\n",
    "    \"./Prod5-North-20deg-AverageAz-4LSTs09MSTs.18000s-v0.1.fits.gz\"\n",
    ")\n",
    "\n",
    "location = observatory_locations[\"cta_north\"]\n",
    "obs = Observation.create(\n",
    "    pointing=pointing,\n",
    "    livetime=livetime,\n",
    "    irfs=irfs,\n",
    "    location=location,\n",
    ")\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u02hNLxlmtDJ"
   },
   "source": [
    "#### Peek at the IRFs\n",
    "\n",
    "We check the effective area, PSF, and energy dispersion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kirqv8bGmtDJ"
   },
   "outputs": [],
   "source": [
    "irfs[\"aeff\"].peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP3NleYimtDJ"
   },
   "outputs": [],
   "source": [
    "irfs[\"edisp\"].peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4uejvNqmtDJ"
   },
   "outputs": [],
   "source": [
    "irfs[\"psf\"].peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrSJSoVZmtDJ"
   },
   "source": [
    "### Simulate a spectra\n",
    "\n",
    "Now we have to follow some steps to simulate the On/Off data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7t_yrnXmtDJ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make the SpectrumDataset\n",
    "geom = RegionGeom.create(region=on_region, axes=[energy_axis])\n",
    "\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    geom=geom, energy_axis_true=energy_axis_true, name=\"obs-0\"\n",
    ")\n",
    "maker = SpectrumDatasetMaker(selection=[\"exposure\", \"edisp\", \"background\"])\n",
    "\n",
    "dataset = maker.run(dataset_empty, obs)\n",
    "\n",
    "# Set the model on the dataset, and fake\n",
    "dataset.models = model_no_alps\n",
    "dataset.fake(random_state=42)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8UDe1KJmtDK"
   },
   "outputs": [],
   "source": [
    "dataset.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoOJj6YvmtDK"
   },
   "source": [
    "You can see that background counts are now simulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0C2O153mtDK"
   },
   "source": [
    "### On-Off analysis\n",
    "\n",
    "To do an on off spectral analysis, which is the usual science case, the\n",
    "standard would be to use `SpectrumDatasetOnOff`, which uses the\n",
    "acceptance to fake off-counts.\n",
    "The `acceptance_off` is essentially the parameter $\\alpha^{-1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7dK1JTNmtDK",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_on_off = SpectrumDatasetOnOff.from_spectrum_dataset(\n",
    "    dataset=dataset, acceptance=1, acceptance_off=5\n",
    ")\n",
    "dataset_on_off.fake(npred_background=dataset.npred_background(), random_state=42)\n",
    "print(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S3jsLtkmtDK"
   },
   "outputs": [],
   "source": [
    "dataset_on_off.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHrsvL10mtDK"
   },
   "source": [
    "### Look at the statistics of the dataset\n",
    "\n",
    "Basic statistics of the dataset like On, Off, excess counds, and the source significance are available from the `info_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5fhqZspmtDK"
   },
   "outputs": [],
   "source": [
    "dataset_on_off.info_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6SE8dq5mtDK"
   },
   "source": [
    "### Perform the fit\n",
    "\n",
    "For our baseline model, without ALPs, we fit the observation with the same model that we used to simulate the data set, i.e., our intrinsic model with EBL absorption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4Oj8DdsmtDK"
   },
   "outputs": [],
   "source": [
    "# init the fit\n",
    "fit = Fit(optimize_opts={\"print_level\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NBjF1WhmtDK"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result_no_alps = fit.run(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F27a7rNJmtDK"
   },
   "outputs": [],
   "source": [
    "# check the best-fit parameters\n",
    "result_no_alps.models[0].spectral_model.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs2miYhvmtDK"
   },
   "source": [
    "The Cash statistic, $C = -2\\ln\\mathcal{L}$, is stored in `results_no_alps.total_stat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSD4JEK5mtDK"
   },
   "outputs": [],
   "source": [
    "result_no_alps.total_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0e_e2qamtDL"
   },
   "source": [
    "One can easily plot the excess counts and the predicted signal counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNgSjJZQmtDL"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax_spectrum, ax_residuals = dataset_on_off.plot_fit()\n",
    "dataset_on_off.plot_masks(ax=ax_spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG1gXH2PmtDL"
   },
   "source": [
    "Before performing the fit with ALPs, we generate flux points, so that we can plot the SED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0lfgrTBmtDL"
   },
   "outputs": [],
   "source": [
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_axis.edges, reoptimize=False, selection_optional=[\"errn-errp\", \"ul\"], source=\"ngc1275\"\n",
    ")\n",
    "flux_points = fpe.run(datasets=dataset_on_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewN0MEMLmtDL"
   },
   "source": [
    "Plot the flux points, define the energy range to flux points with a $\\mathrm{TS}$ values larger than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJJzCEYumtDL"
   },
   "outputs": [],
   "source": [
    "# TS values of flux points\n",
    "ts_values = np.squeeze(flux_points.ts.data)\n",
    "\n",
    "# mask \n",
    "mask_ts = ts_values > 1.\n",
    "\n",
    "# energy range for plotting\n",
    "plot_range = flux_points.energy_axis.edges[:-1][mask_ts][0] * 0.9, flux_points.energy_axis.edges[1:][mask_ts][-1]\n",
    "print(plot_range)\n",
    "\n",
    "# plot the model\n",
    "ax = result_no_alps.models[0].spectral_model.plot(energy_bounds=plot_range, energy_power=2, ls=\"-\")\n",
    "\n",
    "# plot the butterfly, i.e., the model error\n",
    "result_no_alps.models[0].spectral_model.plot_error(energy_bounds=plot_range, energy_power=2, ax=ax)\n",
    "\n",
    "# plot the flux points\n",
    "flux_points.plot(ax=ax, sed_type=\"e2dnde\", color=\"darkorange\")\n",
    "\n",
    "# limit the energy range\n",
    "plt.xlim(plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qlDoPhHmtDL"
   },
   "source": [
    "## Fit with Axion-like particles \n",
    "\n",
    "As a last step, we perform a fit with axion-like particles. For that, we loop through the \n",
    "$B$ field realizations. We first fit and plot one example. Then we perform the loop.\n",
    "\n",
    "First we define a new compound model that includes the ALP effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIfkmecjmtDL"
   },
   "outputs": [],
   "source": [
    "# use the first B field realization\n",
    "alps = models.TemplateSpectralModel(ml.EGeV * u.GeV, pgg[0])\n",
    "\n",
    "# and define the compound model\n",
    "model_obs_with_alps = models.CompoundSpectralModel(model_intrinsic, alps, operator=operator.mul)\n",
    "\n",
    "model_w_alps = models.SkyModel(spectral_model=model_obs_with_alps, name=\"ngc1275\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4hzZgjKmtDL"
   },
   "source": [
    "Let's plot the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v8Xxa3hmtDL"
   },
   "outputs": [],
   "source": [
    "ax = model_intrinsic.plot(energy_bounds=[0.1, 3.] * u.TeV, energy_power=2, ls='--')\n",
    "_ = model_input.plot(energy_bounds=[0.1, 3.] * u.TeV, energy_power=2)\n",
    "_ = model_obs_with_alps.plot(energy_bounds=[0.1, 3.] * u.TeV, energy_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LjEPRvZmtDL"
   },
   "source": [
    "Then we set the model and fit it to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-JqP0MdmtDL"
   },
   "outputs": [],
   "source": [
    "dataset_on_off.models = model_w_alps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUv-O7drmtDL"
   },
   "outputs": [],
   "source": [
    "result_w_alps = fit.run(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "982tI1JnmtDL"
   },
   "outputs": [],
   "source": [
    "# check the best-fit parameters\n",
    "result_w_alps.models[0].spectral_model.parameters.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T00Dc45EmtDL"
   },
   "outputs": [],
   "source": [
    "result_w_alps.total_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdpxauKWmtDM"
   },
   "source": [
    "#### Questions:\n",
    "- What do you notice for the best-fit parameters?\n",
    "- Can you plot the flux points, the best fit without ALPs and the best-fit models with ALPs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyRHcjWFmtDM"
   },
   "outputs": [],
   "source": [
    "# plot the model w/o ALPs\n",
    "ax = result_no_alps.models[0].spectral_model.plot(energy_bounds=plot_range, energy_power=2, ls=\"-\")\n",
    "result_no_alps.models[0].spectral_model.plot_error(energy_bounds=plot_range, energy_power=2, ax=ax)\n",
    "\n",
    "# plot the model w/ ALPs\n",
    "ax = result_w_alps.models[0].spectral_model.plot(energy_bounds=plot_range, energy_power=2, ls=\"-\")\n",
    "result_w_alps.models[0].spectral_model.plot_error(energy_bounds=plot_range, energy_power=2, ax=ax)\n",
    "\n",
    "# plot the flux points\n",
    "flux_points.plot(ax=ax, sed_type=\"e2dnde\", color=\"k\")\n",
    "\n",
    "# limit the energy range\n",
    "plt.xlim(plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jpnLntAmtDM"
   },
   "source": [
    "Lastly, we loop through the magnetic field realizations and perform the fit in each step. \n",
    "We save the $C$ stat value and plot the difference, $\\Delta C = C_\\mathrm{w/~ALP} - C_\\mathrm{no~ALP}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPEZaLSCmtDM"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tot_stat = []\n",
    "\n",
    "fit = Fit(optimize_opts={\"print_level\":1})  # reduce print level\n",
    "\n",
    "for i, p in enumerate(pgg):\n",
    "    \n",
    "    # model\n",
    "    alps = models.TemplateSpectralModel(ml.EGeV * u.GeV, pgg[i])\n",
    "    model_obs_with_alps = models.CompoundSpectralModel(model_intrinsic, alps, operator=operator.mul)\n",
    "    model_w_alps = models.SkyModel(spectral_model=model_obs_with_alps, name=\"ngc1275\")\n",
    "    \n",
    "    # set the model of the dataset\n",
    "    dataset_on_off.models = model_w_alps\n",
    "    \n",
    "    # fit \n",
    "    result_w_alps = fit.run(dataset_on_off)\n",
    "    \n",
    "    # save the total stat value\n",
    "    tot_stat.append(result_w_alps.total_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7jtzcb9mtDM"
   },
   "outputs": [],
   "source": [
    "# convert to np.array\n",
    "tot_stat = np.array(tot_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oBNHT9RmtDM"
   },
   "outputs": [],
   "source": [
    "# plot the histogram\n",
    "llr = tot_stat - result_no_alps.total_stat  # the log likelihood ratio values\n",
    "bins = np.linspace(0, llr.max(), 20)  # bin edges for histogram\n",
    "plt.hist(llr, bins=bins)\n",
    "plt.xlabel(\"$\\Delta C = C_\\mathrm{w/~ALP} - C_\\mathrm{no~ALP}$\")\n",
    "\n",
    "# and the fifth quantile\n",
    "print(int(len(tot_stat) * 0.05))\n",
    "tot_stat_q5 = np.sort(tot_stat)[int(len(tot_stat) * 0.05)]\n",
    "\n",
    "plt.axvline(tot_stat_q5 - result_no_alps.total_stat, ls='--', color='r')\n",
    "print(tot_stat_q5 - result_no_alps.total_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eR0voi92mtDM"
   },
   "source": [
    "### Questions:\n",
    "- How do interpret this histogram?\n",
    "- Which B field realization should we use to decide if the ALP hypothesis is preferred or not?\n",
    "- How do the results change when you change the observation live time?\n",
    "- How do the results change when you change the intrinsic model to a power law?\n",
    "- How do the results change when you change the ALP mass or photon-ALP coupling?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
